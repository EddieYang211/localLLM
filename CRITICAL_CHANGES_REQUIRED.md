# å‡çº§åˆ° b7785 çš„å…³é”®ä¿®æ”¹æ¸…å•

**æ–‡ä»¶**: `custom_files/localllm_capi.cpp`
**å½“å‰ llama.cpp ç‰ˆæœ¬**: b5421
**ç›®æ ‡ç‰ˆæœ¬**: b7785

---

## ğŸš¨ å¿…é¡»ä¿®æ”¹çš„ä»£ç ï¼ˆç ´åæ€§å˜åŒ–ï¼‰

### 1. **KV Cache API â†’ Memory API** âš ï¸ **é«˜ä¼˜å…ˆçº§**

ä½ çš„ä»£ç ä¸­æœ‰ **5 å¤„** ä½¿ç”¨äº†å·²å¼ƒç”¨çš„ `llama_kv_self_*` å‡½æ•°ï¼Œè¿™äº›åœ¨ b7785 ä¸­**å·²é‡å‘½å**ä¸º `llama_memory_*`ã€‚

#### å‘ç°çš„ä½¿ç”¨ä½ç½®ï¼š

| è¡Œå· | å½“å‰ä»£ç  (b5421) | å¿…é¡»æ”¹ä¸º (b7785) |
|------|-----------------|-----------------|
| **372** | `llama_kv_self_clear(ctx);` | `llama_memory_clear(llama_get_memory(ctx), false);` |
| **538** | `llama_kv_self_clear(ctx);` | `llama_memory_clear(llama_get_memory(ctx), false);` |
| **577** | `llama_kv_self_clear(ctx);` | `llama_memory_clear(llama_get_memory(ctx), false);` |
| **749** | `llama_kv_self_seq_rm(ctx, slot.seq_id, 0, -1);` | `llama_memory_seq_rm(llama_get_memory(ctx), slot.seq_id, 0, -1);` |
| **837** | `llama_kv_self_seq_cp(ctx, 0, slot.seq_id, -1, -1);` | `llama_memory_seq_cp(llama_get_memory(ctx), 0, slot.seq_id, -1, -1);` |
| **842** | `llama_kv_self_seq_rm(ctx, slot.seq_id, 0, -1);` | `llama_memory_seq_rm(llama_get_memory(ctx), slot.seq_id, 0, -1);` |
| **1078** | `llama_kv_self_seq_rm(ctx, 0, 0, -1);` | `llama_memory_seq_rm(llama_get_memory(ctx), 0, 0, -1);` |
| **1106** | `llama_kv_self_clear(ctx);` | `llama_memory_clear(llama_get_memory(ctx), false);` |

#### è¯¦ç»†ä¿®æ”¹æ–¹æ¡ˆï¼š

**ä½ç½® 1: localllm_generate() ç¬¬ 372 è¡Œ**
```cpp
// b5421 (æ—§)
llama_kv_self_clear(ctx);

// b7785 (æ–°)
llama_memory_t mem = llama_get_memory(ctx);
llama_memory_clear(mem, false);
```

**ä½ç½® 2-4: localllm_generate_parallel() å¤šå¤„**
```cpp
// åœ¨å‡½æ•°å¼€å§‹å¤„æ·»åŠ  memory å¥æŸ„
llama_memory_t mem = llama_get_memory(ctx);

// ç„¶åæ›¿æ¢æ‰€æœ‰è°ƒç”¨ï¼š
// ç¬¬ 538 è¡Œ
llama_memory_clear(mem, false);

// ç¬¬ 577 è¡Œï¼ˆé”™è¯¯å¤„ç†ä¸­ï¼‰
llama_memory_clear(mem, false);

// ç¬¬ 749 è¡Œ
llama_memory_seq_rm(mem, slot.seq_id, 0, -1);

// ç¬¬ 837 è¡Œ
llama_memory_seq_cp(mem, 0, slot.seq_id, -1, -1);

// ç¬¬ 842 è¡Œ
llama_memory_seq_rm(mem, slot.seq_id, 0, -1);

// ç¬¬ 1078 è¡Œ
llama_memory_seq_rm(mem, 0, 0, -1);

// ç¬¬ 1106 è¡Œï¼ˆå¼‚å¸¸å¤„ç†ï¼‰
llama_memory_clear(mem, false);
```

---

### 2. **å‚æ•°ç»“æ„ä½“å·²é»˜è®¤åˆå§‹åŒ–** âœ… **å·²æ­£ç¡®å®ç°**

**å¥½æ¶ˆæ¯**: ä½ çš„ä»£ç å·²ç»æ­£ç¡®ä½¿ç”¨äº†é»˜è®¤å‚æ•°åˆå§‹åŒ–ï¼

#### ç¬¬ 166 è¡Œ - localllm_model_load()
```cpp
llama_model_params model_params = llama_model_default_params();  // âœ… æ­£ç¡®
model_params.n_gpu_layers = n_gpu_layers;
model_params.use_mmap = use_mmap;
model_params.use_mlock = use_mlock;
```

#### ç¬¬ 224 è¡Œ - localllm_model_load_safe()
```cpp
llama_model_params model_params = llama_model_default_params();  // âœ… æ­£ç¡®
model_params.n_gpu_layers = n_gpu_layers;
model_params.use_mmap = use_mmap;
model_params.use_mlock = use_mlock;
```

#### ç¬¬ 264 è¡Œ - localllm_context_create()
```cpp
llama_context_params ctx_params = llama_context_default_params();  // âœ… æ­£ç¡®
ctx_params.n_ctx = n_ctx;
ctx_params.n_threads = n_threads;
ctx_params.n_seq_max = n_seq_max;
```

**è¿™äº›éƒ½ä¸éœ€è¦ä¿®æ”¹ï¼** ğŸ‰

---

### 3. **llama_decode() é”™è¯¯å¤„ç†** ğŸ”§ **å»ºè®®æ”¹è¿›ï¼ˆå¯é€‰ï¼‰**

ä½ çš„ä»£ç å½“å‰åªæ£€æŸ¥ `!= 0`ï¼Œè¿™åœ¨ b7785 ä»ç„¶æœ‰æ•ˆï¼Œä½†å¯ä»¥æ”¹è¿›ä»¥æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ã€‚

#### å½“å‰å®ç°ï¼ˆç¬¬ 378, 477, 562, 712, 927 è¡Œï¼‰:
```cpp
if (llama_decode(ctx, batch) != 0) {
    set_error(error_message, "Failed to decode input tokens.");
    return LOCALLLM_ERROR;
}
```

#### å»ºè®®çš„æ”¹è¿›ï¼ˆå¯é€‰ï¼‰:
```cpp
int ret = llama_decode(ctx, batch);
if (ret != 0) {
    std::string error_detail;
    switch (ret) {
        case 1:
            error_detail = "No KV slot available - try reducing batch size or increasing n_ctx";
            break;
        case 2:
            error_detail = "Decoding aborted - partial results may be available";
            break;
        case -1:
            error_detail = "Invalid input batch";
            break;
        default:
            error_detail = ret < -1 ? "Fatal error during decoding" : "Unknown decode error";
    }
    set_error(error_message, "Failed to decode: " + error_detail);
    return LOCALLLM_ERROR;
}
```

**è¿™ä¸ªæ”¹è¿›ä¸æ˜¯å¿…é¡»çš„**ï¼Œä½†ä¼šæä¾›æ›´å¥½çš„é”™è¯¯ä¿¡æ¯ã€‚

---

## ğŸ“‹ å®Œæ•´ä¿®æ”¹æ¸…å•

### å¿…é¡»ä¿®æ”¹ (Breaking Changes)

- [x] **ç¬¬ 372 è¡Œ**: `llama_kv_self_clear(ctx)` â†’ Memory API
- [x] **ç¬¬ 538 è¡Œ**: `llama_kv_self_clear(ctx)` â†’ Memory API
- [x] **ç¬¬ 577 è¡Œ**: `llama_kv_self_clear(ctx)` â†’ Memory API
- [x] **ç¬¬ 749 è¡Œ**: `llama_kv_self_seq_rm()` â†’ Memory API
- [x] **ç¬¬ 837 è¡Œ**: `llama_kv_self_seq_cp()` â†’ Memory API
- [x] **ç¬¬ 842 è¡Œ**: `llama_kv_self_seq_rm()` â†’ Memory API
- [x] **ç¬¬ 1078 è¡Œ**: `llama_kv_self_seq_rm()` â†’ Memory API
- [x] **ç¬¬ 1106 è¡Œ**: `llama_kv_self_clear(ctx)` â†’ Memory API

### å¯é€‰æ”¹è¿›

- [ ] æ”¹è¿› `llama_decode()` é”™è¯¯å¤„ç†ï¼ˆ5 å¤„ï¼‰
- [ ] æ·»åŠ  Flash Attention æ”¯æŒï¼ˆåœ¨ `localllm_context_create` ä¸­ï¼‰
- [ ] ä½¿ç”¨æ–°çš„æ¨¡å‹ä¿¡æ¯æŸ¥è¯¢å‡½æ•°

---

## ğŸ”§ å…·ä½“ä¿®æ”¹ä»£ç 

### ä¿®æ”¹ 1: localllm_generate() å‡½æ•°

**ä½ç½®**: ç¬¬ 365-485 è¡Œ

```cpp
LOCALLLM_API localllm_error_code localllm_generate(...) {
    if (!ctx) {
        set_error(error_message, "Context handle is null.");
        return LOCALLLM_ERROR;
    }

    // ä¿®æ”¹è¿™é‡Œ â¬‡ï¸
    llama_memory_t mem = llama_get_memory(ctx);
    llama_memory_clear(mem, false);  // æ›¿ä»£æ—§çš„ llama_kv_self_clear(ctx)

    const llama_model* model = llama_get_model(ctx);
    // ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
}
```

### ä¿®æ”¹ 2: localllm_generate_parallel() å‡½æ•°

**ä½ç½®**: ç¬¬ 488-1110 è¡Œ

```cpp
LOCALLLM_API localllm_error_code localllm_generate_parallel(...) {
    if (!ctx || !prompts || !params || !results_out || n_prompts <= 0) {
        set_error(error_message, "Invalid parameters...");
        return LOCALLLM_ERROR;
    }

    // æ·»åŠ è¿™ä¸€è¡Œ â¬‡ï¸
    llama_memory_t mem = llama_get_memory(ctx);

    const llama_model* model = llama_get_model(ctx);
    // ...

    // ç¬¬ 538 è¡Œé™„è¿‘ï¼šæ›¿æ¢
    llama_memory_clear(mem, false);  // æ›¿ä»£ llama_kv_self_clear(ctx)

    // ç¬¬ 577 è¡Œé™„è¿‘ï¼šæ›¿æ¢
    if (!prefix_ok) {
        llama_memory_clear(mem, false);  // æ›¿ä»£ llama_kv_self_clear(ctx)
    }

    // ç¬¬ 749 è¡Œé™„è¿‘ï¼šfinalize_slot å‡½æ•°ä¸­
    if (slot.seq_id > 0) {
        llama_memory_seq_rm(mem, slot.seq_id, 0, -1);  // æ›¿ä»£ llama_kv_self_seq_rm
    }

    // ç¬¬ 837 è¡Œé™„è¿‘ï¼šassign_next_prompt å‡½æ•°ä¸­
    if (prefix_ready && slot.prefix_len > 0) {
        llama_memory_seq_cp(mem, 0, slot.seq_id, -1, -1);  // æ›¿ä»£ llama_kv_self_seq_cp
    }

    // ç¬¬ 842 è¡Œé™„è¿‘ï¼š
    if (slot.seq_id > 0) {
        llama_memory_seq_rm(mem, slot.seq_id, 0, -1);  // æ›¿ä»£ llama_kv_self_seq_rm
    }

    // ç¬¬ 1078 è¡Œé™„è¿‘ï¼š
    if (prefix_ready) {
        llama_memory_seq_rm(mem, 0, 0, -1);  // æ›¿ä»£ llama_kv_self_seq_rm
    }

    // ... å…¶ä½™ä»£ç 

    } catch (const std::exception& e) {
        if (show_progress_bar) { /* ... */ }
        llama_memory_clear(mem, false);  // æ›¿ä»£ llama_kv_self_clear(ctx)
        set_error(error_message, std::string("Parallel generation failed: ") + e.what());
        return LOCALLLM_ERROR;
    }
}
```

---

## ğŸ¯ å¯é€‰çš„æ€§èƒ½ä¼˜åŒ–

### 1. Flash Attention æ”¯æŒ

åœ¨ `localllm_context_create()` ä¸­æ·»åŠ ï¼š

```cpp
LOCALLLM_API localllm_error_code localllm_context_create(...) {
    // ...
    llama_context_params ctx_params = llama_context_default_params();
    ctx_params.n_ctx = n_ctx;
    ctx_params.n_threads = n_threads;
    ctx_params.n_seq_max = n_seq_max;

    // æ–°å¢ï¼šå¯ç”¨ Flash Attentionï¼ˆå¯é€‰ï¼Œæå‡æ€§èƒ½ï¼‰
    ctx_params.flash_attn_type = LLAMA_FLASH_ATTN_TYPE_AUTO;  // è‡ªåŠ¨æ£€æµ‹

    llama_context* ctx = llama_init_from_model(model, ctx_params);
    // ...
}
```

### 2. ç»Ÿä¸€ KV Bufferï¼ˆå¤šåºåˆ—åœºæ™¯ä¼˜åŒ–ï¼‰

```cpp
// å¦‚æœç”¨æˆ·ä½¿ç”¨ n_seq_max > 1
if (n_seq_max > 1) {
    ctx_params.kv_unified = true;  // å…±äº«å‰ç¼€ç¼“å­˜
}
```

---

## âœ… æµ‹è¯•éªŒè¯æ¸…å•

å®Œæˆä¿®æ”¹åï¼Œæµ‹è¯•ä»¥ä¸‹åŠŸèƒ½ï¼š

### åŸºç¡€åŠŸèƒ½æµ‹è¯•
- [ ] `localllm_backend_init()` æˆåŠŸ
- [ ] `localllm_model_load()` åŠ è½½æ¨¡å‹
- [ ] `localllm_context_create()` åˆ›å»ºä¸Šä¸‹æ–‡
- [ ] `localllm_tokenize()` / `localllm_detokenize()` æ­£å¸¸å·¥ä½œ

### ç”Ÿæˆæµ‹è¯•
- [ ] `localllm_generate()` å•æ¬¡ç”Ÿæˆæ­£å¸¸
- [ ] `localllm_generate_parallel()` å¹¶è¡Œç”Ÿæˆæ­£å¸¸
- [ ] å¤šæ¬¡è°ƒç”¨ `generate()` ç»“æœä¸€è‡´ï¼ˆKV cache æ¸…ç©ºç”Ÿæ•ˆï¼‰

### KV Cache/Memory æµ‹è¯•
- [ ] å•åºåˆ—ç”Ÿæˆå memory è¢«æ­£ç¡®æ¸…ç©º
- [ ] å¤šåºåˆ—å¹¶è¡Œç”Ÿæˆäº’ä¸å¹²æ‰°
- [ ] å…±äº«å‰ç¼€ä¼˜åŒ–ç”Ÿæ•ˆï¼ˆå¦‚æœä½¿ç”¨ï¼‰

### é”™è¯¯å¤„ç†æµ‹è¯•
- [ ] è¶…å‡ºä¸Šä¸‹æ–‡é•¿åº¦æ—¶è¿”å›æ­£ç¡®é”™è¯¯
- [ ] æ— æ•ˆè¾“å…¥æ—¶è¿”å›æ­£ç¡®é”™è¯¯
- [ ] å†…å­˜ä¸è¶³æ—¶è¿”å›æ­£ç¡®é”™è¯¯

---

## ğŸ“Š é£é™©è¯„ä¼°

| ä¿®æ”¹é¡¹ | å¤æ‚åº¦ | ç ´åé£é™© | æµ‹è¯•éš¾åº¦ |
|-------|--------|---------|---------|
| KV Cache â†’ Memory API | ğŸŸ¡ ä¸­ | ğŸ”´ é«˜ | ğŸŸ¢ ä½ |
| å‚æ•°ç»“æ„ä½“åˆå§‹åŒ– | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ |
| é”™è¯¯å¤„ç†æ”¹è¿› | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ |
| Flash Attention | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ | ğŸŸ¡ ä¸­ |

**æ€»ä½“é£é™©**: ğŸŸ¡ **ä¸­ç­‰**ï¼ˆä¸»è¦æ¥è‡ª KV Cache API é‡æ„ï¼‰

---

## ğŸš€ æ¨èçš„å®æ–½æ­¥éª¤

1. **å¤‡ä»½å½“å‰æ–‡ä»¶**
   ```bash
   cp custom_files/localllm_capi.cpp custom_files/localllm_capi.cpp.b5421.backup
   ```

2. **åˆ‡æ¢åˆ° b7785**
   ```bash
   cd backend/llama.cpp
   git checkout b7785
   ```

3. **ä¿®æ”¹ localllm_capi.cpp**
   - ä½¿ç”¨æŸ¥æ‰¾æ›¿æ¢åŠŸèƒ½å¿«é€Ÿä¿®æ”¹æ‰€æœ‰ `llama_kv_self_*` è°ƒç”¨
   - åœ¨å‡½æ•°å¼€å§‹æ·»åŠ  `llama_memory_t mem = llama_get_memory(ctx);`

4. **ç¼–è¯‘åç«¯åº“**
   ```bash
   cd backend/llama.cpp
   mkdir -p build && cd build
   cmake .. -DCMAKE_BUILD_TYPE=Release -DGGML_METAL=ON -DBUILD_SHARED_LIBS=ON
   cmake --build . --config Release -j $(sysctl -n hw.ncpu)
   ```

5. **åœ¨ R ä¸­æµ‹è¯•**
   ```r
   library(localLLM)
   install_localLLM()  # å®‰è£…æ–°ç¼–è¯‘çš„åº“

   # æµ‹è¯•åŸºç¡€åŠŸèƒ½
   model <- model_load("path/to/model.gguf")
   ctx <- context_create(model, n_ctx = 512)
   result <- generate(ctx, "Test", max_tokens = 10)
   print(result)
   ```

6. **è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶**
   ```bash
   cd localLLM
   R CMD check .
   ```

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœåœ¨ä¿®æ”¹è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
- âœ… æ‰€æœ‰ `llama_kv_self_*` è°ƒç”¨éƒ½å·²æ›¿æ¢
- âœ… æ¯ä¸ªä½¿ç”¨ Memory API çš„å‡½æ•°éƒ½æœ‰ `llama_memory_t mem = llama_get_memory(ctx)`
- âœ… `llama_memory_clear()` çš„ç¬¬äºŒä¸ªå‚æ•°æ˜¯ `false`
- âœ… ç¼–è¯‘æ—¶æ²¡æœ‰ undefined symbol é”™è¯¯

---

**é¢„è®¡å·¥ä½œæ—¶é—´**: 1-2 å°æ—¶ï¼ˆä»£ç ä¿®æ”¹ + ç¼–è¯‘æµ‹è¯•ï¼‰

**æˆåŠŸæŒ‡æ ‡**:
- âœ… ç¼–è¯‘æ— é”™è¯¯
- âœ… æ‰€æœ‰ R æµ‹è¯•é€šè¿‡
- âœ… `generate()` å’Œ `generate_parallel()` ç»“æœæ­£ç¡®
- âœ… å¤šæ¬¡è¿è¡Œç»“æœä¸€è‡´ï¼ˆç¡®è®¤ memory æ¸…ç©ºç”Ÿæ•ˆï¼‰
